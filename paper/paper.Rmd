---
title: Open-source tools in R for landscape ecology
authors: 
- name: Maximillian H.K. Hesselbarth
  address:
    a) Department of Ecosystem Modelling, University of Goettingen, Buesgenweg 4, 37077 Goettingen, Germany
    b) Department of Ecology and Evolutionary Biology, University of Michigan, Ann Arbor, MI, 48109, USA
  email: mhk.hesselbarth@gmail.com
- name: Jakub Nowosad
  address: Institute of Geoecology and Geoinformation, Adam Mickiewicz University, Krygowskiego 10, 61-680 Poznan, Poland
  email: nowosad.jakub@gmail.com
- name: Johannes Signer
  address: Wildlife Sciences, Faculty of Forestry and Forest Ecology, University of Goettingen, Buesgenweg 3, 37077 Goettingen, Germany
  email: jsigner@uni-goettingen.de
- name: Laura J. Graham
  address: 
    a) Geography, Earth & Environmental Sciences, University of Birmingham, Edgbaston, Birmingham B15 2TT, United Kingdom
    b) Biodiversity, Ecology & Conservation Group, IIASA, Vienna, Austria 
  email: l.graham@bham.ac.uk
keywords:
- spatial data
- statistical programming language
- R packages
- reproducibility
- scientific software
abstract: |
  **Purpose of review** Landscape ecology, the study of the complex interactions between landscapes and ecological processes, has hugely benefited from the increase in widely available open source software in recent years. In particular, the *R* programming language provides a wealth of community developed tools for landscape ecology. **Recent findings** In this paper, we outline existing packages for the downloading, processing and visualisation of spatial data, as well as those specifically developed for ecological analysis. Additionally, we outline the results of a survey of *R* users within the landscape ecology community. **Summary** In this we find that landscape ecologists are generally satisfied with the functionality available within *R*, and that as a community they are continually updating the functionality available. Suggested future developments include improvement of computation performance; additional methods for landscape characterisation such as surface metrics; and advanced, accessible visualisation tools. 
bibliography: bibliography.bib
bibstyle: spphys # bibstyle options spbasic(default), spphys, spmpsci
preamble: |
  \usepackage{caption}
  \usepackage{tabularx}
  \usepackage{multirow}
  \usepackage{placeins}
  \usepackage[modulo]{lineno}
output:
  bookdown::pdf_book:
    base_format: rticles::springer_article
    number_sections: yes
    citation_package: default
editor_options:
  chunk_output_type: console
  markdown:
    wrap: sentence
---

```{r setup R, include = FALSE}
# load packages
library(dplyr)
library(forcats)
library(ggplot2)
library(googlesheets4)
library(knitr)
library(patchwork)
library(stringr)
library(tibble)
library(tidyr)

# MAKE SURE TO RUN R/get_survey_data.R TO GET NEWST SURVERY RESULTS

results <- readRDS("data/results.rds")

answers <- results$answers

old_names <- results$old_names

new_names <- results$new_names

base_size <- 7.5
```

\linenumbers

# Introduction {#sec:intro}

\begin{tabularx}{450pt}{lX}

\hline

\multicolumn{2}{c}{Glossary} \\

\hline

API & Application programming interface. A set of protocols for sending and retrieving information from a server \\
cell & Smallest, rectangular unit of raster data model \\
CRAN & Comprehensive R Archive Network. A repository for *R* package \\
CRS & Coordinate references systems. A coordinate-based local, regional or global system used to locate geographical entities \\
EPSG & Public registry of geodetic datums, spatial reference systems, Earth ellipsoids, coordinate transformations and related units of measurement \\
GDAL & Open source translator library for raster and vector geospatial data formats \\
GIS & Geographical information system \\
landscape & Mosaic of land covers, ecosystems, habitat types, land uses \\
NLM & Neutral landscape model \\
open-source software & Software released under licenses that allow to use, modify and distribute it \\
patch & Neighboring cells with same value \\
PROJ & Open source generic coordinate transformation software \\
raster & Cell grid based data model \\
resolution & Size in meter or degree of one cell \\
*R* package & User-created software extension to *R* programming language \\
SDM & Species distribution modelling \\
Simple Features & A set of standards that specify a common storage and access model of geographic features \\
vector & Points, lines, and polygons-based data model \\

\hline

\end{tabularx}

## A short introduction to landscape ecology {#sec:landscape_ecology}

While human activities have altered the landscapes for millennia \cite{Ellis2011,Ellis2015}, in the recent centuries, the effects of humans on landscapes have increased to an unknown high, known as the Anthropocene \cite{Crutzen2002}.
Today, almost all landscapes are directly or indirectly influenced by human activities \cite{Vitousek1997}.
Thus, understanding the complex interactions between landscapes and ecological processes becomes increasingly important for science, conservation, or management \cite{With2019}.

Landscape ecology focuses on how ecological processes are influenced by the heterogeneous landscapes they occur in and how the ecological processes themselves influence the landscapes \cite{Turner1989,Turner2005,With2019}.
In this context, landscape ecology predominantly focuses on i) spatial and temporal dynamics of heterogeneous landscapes, ii) interactions, fluxes, and exchanges within these landscapes, iii) how the landscapes influence ecological processes (and vice versa), and lastly, iv) and can guide how to manage these heterogeneous landscapes \cite{Risser1984,Turner1989}.

Because landscapes are defined as mosaics of different land covers, ecosystems, habitat types, or land uses \cite{Forman1986,Forman1995,Wiens1995}, spatial context is important and ecological processes can vary spatially \cite{With2019}.
The importance of scale was already raised decades ago \cite{Wiens1989,Levin1992,Jelinski1996} and is still of relevance today \cite{Simova2012,Estes2018}.
Thus, landscape ecology emphasizes spatial patterns to a high degree \cite{Risser1984} and consequently relies on software to preprocess, modify, model, analyze, and visualize spatial data.

## Open-source software and *R* {#sec:open_source}

Software to manage and analyze data becomes increasingly important in modern scientific research \cite{Wilson2014} and many scientific studies would not have been possible without open-source software \cite{Prlic2012}.
Open-source software includes all software that is released under licenses that allow to use, modify and distribute the software \cite{St.Laurent2008}.
Open-source software development has many advantages, such as fast innovation, transparency, reliability, and longevity, mainly due to many diverse contributors \cite{vonKrogh2006,St.Laurent2008}.
Additionally, the use of open-source software facilitates (computational) reproducibility and can allow a better understanding of the methodology of a study \cite{Prlic2012,Powers2019}.
Furthermore, open-source software allows other scientists to reuse code and not "reinvent the wheel" \cite{Prlic2012} by customizing existing software to their specific needs \cite{Steiniger2009}.
Importantly, though not strictly necessary by definition of open-source \cite{Steiniger2009,Steiniger2009a}, most open-source software is also free-of-cost, in contrast to often expensive proprietary software \cite{vonKrogh2006,Steiniger2009,Steiniger2009a}.
This democratizes scientific research as free-of-cost software removes one gatekeeper for researchers without access to proprietary software.

One successful example of an open-source project is the *R* programming language, and its extensions called packages \cite{RCoreTeam2019}.
Firstly released in 1995 \cite{Smith2016}, today the programming language is among the most popular programming languages, especially in ecology \cite{Lai2019}.
Originally introduced as a statistical programming language, a growing body of packages designed to analyze spatial data subsequently emerged for the *R* programming language \cite{Bivand2006,Lovelace2019}.
The expanding CRAN Task Views (curated lists of packages related to a certain topic) document this: *Analysis of Spatial Data* \cite{Bivand2019a} and *Handling and Analyzing Spatio-Temporal Data* \cite{Pebesma2020} currently list about 300 packages in total.
Since the task views are maintained manually by just a few people, the actual amount of *R* packages related to spatial data is most likely higher.
The growing popularity of the *R* programming language for spatial data analysis and landscape ecology can also be seen with the increasing number of related textbooks \cite{Wegmann2016,Fletcher2019,Lovelace2019,Pebesma2019a}.
A recent overview over the progress of *R* to handle spatial data in general can be found in \cite{Bivand2020}.

Even though many other open-source tools \cite{QGISDevelopmentTeam2016,GRASSDevelopmentTeam2017,Porta2017} and suitable programming languages (e.g. Python) for landscape ecology exist, in this review we focus on software implemented in the *R* programming language.
For more general overviews of open-source software for landscape ecology see \cite{Jolma2008,Steiniger2009,Steiniger2009a,Istvan2012}.
The *R* programming language can be a very powerful tool. In addition to handling spatial data, other analytical tasks such as statistical modeling, creation of publication-ready figures, and even complete reports can be done within the *R* environment (Fig. \@ref(fig:fig-workflow)).
The growing body of *R* packages related to spatial data processing and analysis results in a high capability of this language for landscape ecology.

Thus, in the first part of this article, we present an overview of existing *R* packages for landscape ecology and closely related fields (Table \@ref(tab:packages)).
In the second part, we present a survey in which we asked the community how they currently use the *R* programming language and to identify topics for which *R* packages are presently missing for landscape ecology.

# Existing packages {#sec:existing_packages}

Most *R* packages are developed and maintained by the community, which shows how open-source software development can facilitate innovation, reproducibility, and reuse of code.
There are three major online platforms to host *R* packages and make them accessible to potential users: CRAN, GitHub, and Bioconductor.
The last one focuses on tools for the analysis of genomic data; therefore, we focus on only the former two in this review.
CRAN (the *Comprehensive R Archive Network*) provides large visibility to the community, ease of installation, and a technical quality standard, including checks for common problems on all major operating systems \cite{Wickham2015}.
*GitHub* hosts source code under version control, and allows users to install packages with one line of code using the *remotes* \cite{Hester2020} package.
Additionally, hosting a package on *GitHub* provides many useful features to collaborate and communicate between developers and users \cite{Wickham2015}, or integrated unit testing (i.e. testing if functions return an expected value).

The guaranteed technical quality standard of *CRAN* requires more initial work for developers compared to *GitHub*, while it ensures for users that the package can be installed on their machine.
Additionally, the technical quality standard of *CRAN* also facilitates reproducibility and reuse of code, as shown by many reverse dependencies of *R* packages, i.e., package *x* requires and uses code from package *y*.
CRAN also provides archived versions of outdated or orphaned packages and thus ensuring long term availability and reproducibility of code.
Thus, most packages can be found on both platforms, and many developers use *GitHub* for regular development and *CRAN* to publish stable releases of the packages.
Furthermore, online communities like *rOpenSci* also provide a peer-review process for code quality.
However, while the package environment has many advantages, its highly dynamic characteristic with constant updates by the community might also be a threat to reproducibility since backwards compatibility is not always ensured.
Packages that deal with such issue include *groundhog* \cite{Simonsohn2021}, *packrat* \cite{Ushey2018}, or *renv* \cite{Ushey2020}.
For more information about *R* package development in general, see \cite{Wickham2015}.

```{r fig-workflow, echo = FALSE, out.width="100%", out.height="30%", fig.cap = "Exemplary workflow of spatial data analyses for landscape ecology using the R programming language. For all major tasks, some example R packages are listed."}
include_graphics("data/Workflow.png")
```

## Spatial data representations {#sec:spatrep}

While *R* has several built-in data structures, including vectors, matrices, data frames, and lists, it has no internal support for reading, processing, or visualizing spatial data.
However, because there is a substantial interest in spatial data analysis, support for spatial data is now provided by many *R* packages (\cite{Lovelace2019}, page 10, Table \@ref(tab:packages)).
Most spatial data belong to one of two data models, namely spatial raster and spatial vector model, and both data models have several implementations in the *R* language.
Importantly, main *R* packages for spatial data use the external *GDAL* \cite{GDAL} and *PROJ* \cite{PROJ} libraries, which allow for reading and writing of hundreds of spatial data formats, and coordinates transformation.
Additionally, *R* allows for conversion between data models and specific implementations, which can be useful if given methods only exist for a particular data model or implementation.

In the raster data model, surfaces are divided into cells, where each cell stores a numeric value.
The values could represent discrete phenomena, such as a class number of a land cover category, or continuous phenomena, such as elevation values.
Currently, the most prominent package allowing for raster data representation is *raster* \cite{Hijmans2019}.
A *raster* successor, *terra*, aimed at the simpler interface and improved performance is being developed \cite{R-terra}, however, it could take several years for this package to be adopted by other developers and users.
Alternatively, the *stars* package can be used to read and process raster data focusing on spatial-temporal data cubes \cite{Pebesma2019}.
Additionally, there are packages that improve some basic raster operations in terms of computational performance or compatibility between raster and vector operations, such as *fasterize* \cite{Ross2020}, *rasterDT* \cite{OBrien2020}, or *exactextractr* \cite{Baston2020}.

The vector data model consists of two main elements i) geometries (such as points, lines, polygons) and ii) attributes, where each geometry is connected to a row in the attribute table.
In many cases, this data model allows a more realistic representation of landscape features, however, with the cost of higher computational demands \cite{Lovelace2019}.
The *sp* package was the standard for vector data representation for more than ten years \cite{Pebesma2005,Bivand2013}.
As of 2020, more than 500 *R* packages directly depend or imports *sp*.
However, *sp* is not actively developed anymore, and its recommended successor is the *sf* package \cite{Pebesma2018}.
Besides many advantages and strength of the *sf* package in terms of spatial data handling, it also integrates into the widely used *tidyverse* packages \cite{Wickham2019a}.
*sf* builds on the idea of "simple features", a standard used to describe spatial geometries using points, lines (two connected points) and polygons (several connected points) and attributes connected to these geometries \cite{Pebesma2019a}.

## Spatial data download

Nowadays, spatial data at many scales is available from an abundance of online-accessible sources.
A lot of this data are publicly available, either as a direct download or through an API connection, and several packages can use this to download the spatial data directly into an *R* session.
Since publicly available data is becoming more prominent, so are *R* packages to access them.
Packages include *rnaturalearth* \cite{South2017} to access the Natural Earth database to download region and country data, the *elevatr* package to access raster elevation data \cite{R-elevatr}, the *rgbif* package to access the Global Biodiversity Information Facility (GBIF) portal \cite{R-rgbif}, the *BIEN* package \cite{Maitner2020} to access the Botanical Information and Ecology Network Database, the *marmap* to download bathymetry data from the ETOPO1 database \cite{Pante2013}, or the *FedData* package \cite{R-FedData} to access the National Land Cover Database (NLCD) data for the USA.
Furthermore, the *getlandsat* package \cite{Chamberlain2018} allows users to download Landsat 8 satellite data, the *MODIS* package \cite{Mattiuzzi2020} to download MODIS products, and *sen2r* \cite{R-sen2r} to download Sentinel-2 optical images.
Also, the `getData()` function from the *raster* package allows users to download climatic and bioclimatic data from WorldClim v1.4.
Additionally, the *rgee* package \cite{R-rgee} gives access to an extensive catalog of data from Google Earth Engine, including climate data, land cover maps, and satellite imagery.

## Spatial data processing

Coordinate references systems (CRS) describe how spatial data is projected from the earth's three-dimensional surface to a two-dimensional surface as required for spatial analysis or creating maps \cite{Lovelace2019,Pebesma2019a}.
This is also referred to as the spatial projection and is often the first barrier in spatial data analysis.
It is not only required to have all of the used data in the same projection, but also to select a proper CRS.
This is of importance because the projection into a two-dimensional surface unavoidable leads to distortion, and different CRS are optimized for different properties, regions of the world, and scales \cite{Bivand2013,Lovelace2019}.
Coordinates in spatial data represent one of many coordinate reference systems.
Two main groups of CRS, namely geographical and projected, exist, with each having many members.
Using geographical CRS, positions are specified by latitude and longitude coordinates in degrees.
However, most landscape ecology studies should utilize projected CRSs, which use some measurement units (e.g., meters).
The selection of projected CRS should be based on the property of spatial data that needs to be kept intact (e.g., no distortion of areas, shapes, distances, or angles) and be appropriate for a given study area.
A common way to refer to different CRS is to used codes developed by the European Petrol Survey Group (EPSG).
Tools to find an appropriate CRS for a certain region can be found at <https://spatialreference.org>, <https://epsg.org>, or <http://epsg.io>.
All packages from Section \@ref(sec:spatrep) have interfaces for coordinates transformations, allowing unification of spatial projections when the used data have different CRS.

Another common spatial data processing task is required when the available data extends over a larger area than the study region.
In this case, the pre-processing of spatial data should include vector clipping or raster cropping.
Related to that, masking certain areas of the study region using spatial filters (e.g. water bodies, urban areas) can be required.
Packages from Section \@ref(sec:spatrep) also allow for these operations.
Additionally, they offer many other operations, such as merging or joining spatial data, extracting values from one dataset into another, raster resolution changes, or vector data simplifications.
A comprehensive collection of methods to aggregate raster values to a coarser resolution can also be found in the *grainchanger* package \cite{Graham2019}.
Furthermore, *landscapetools* is a collection of various utility functions for the raster data model \cite{Sciaini2018}.

Finally, there are a number of tools for landscape ecology implemented in GIS software, such as `r.li` or `r.pi` for GRASS GIS \cite{wegmann2018r,neteler2012grass,Porta2017}, terrain analysis methods in SAGA GIS \cite{gmd-8-1991-2015}, or morphological operations for Google Earth Engine.
It is possible to control several GIS software directly from *R* using dedicated packages, such as *rgrass7* \cite{R-grass7} for GRASS GIS, *RSAGA* \cite{R-RSAGA} for SAGA GIS, and *rgee* \cite{R-rgee} for Google Earth Engine.

## Creating maps

Creating maps is essential when working with spatial data.
Maps play an important role in checking the spatial and value-related quality of data, data exploration, and finally communicating results.
*R* allows two major types of maps.
Firstly, static maps in which the developer has full control over the presentation of the map and secondly, interactive maps in which the user has the possibility to modify the map by e.g. changing the displayed values.
All packages listed in Section \@ref(sec:spatrep) have build-in methods for plotting spatial data using the generic `plot()` function.
However, the generic functions are focused on quick visual inspection of the data, rather than the creating complete maps.

Further plotting methods for raster objects can be found in the *rasterVis* package \cite{Lamigueiro2020}.
Also the popular plotting package *ggplot2* \cite{Wickham2016a} has an extension especially designed for plotting spatial data named *ggspatial* \cite{R-ggspatial}.
Static thematic maps, including proportional symbols, choropleth, or typology maps, can be created with the *cartography* package \cite{Giraud2016}.
The *tmap* package provides a coherent plotting system for static and interactive maps that is based on the layered grammar of graphics \cite{Tennekes2018} and aims for creating publication-ready maps.
Quick interactive visualization of spatial data can be done with the *mapview* package\cite{R-mapview}.
Both, *tmap* and *mapview* build upon the *leaflet* package and leaflet javascript library \cite{R-leaflet}.
A slightly different approach to visualizing spatial data is adapted by the *rayshader* package \cite{Morgen-Wall2020} that creates topographic 2D and 3D maps.

```{r fig-map, echo = FALSE, out.width="100%", out.height="50%", fig.cap = "Comparison of different options to create maps using a) base plot, b) ggplot2, and c) tmap. All maps show the total annual precipitation of Switzerland. Data was downloaded with the raster (precipitation data) and rnaturalearth (country borders) package. The code to create the maps can be found in the Appendix."}
include_graphics("data/plot_all.pdf")
```

## Ecological analysis {#sec:ecological_analysis}

#### Quantify landscape characteristics {#sec:landscape_metrics}

One of the most fundamental steps of landscape ecology analyses is to describe and quantify landscape characteristics \cite{Turner2005,Lausch2015}.
For discrete land cover classes, the composition (number and abundance) and configuration (spatial arrangement) of the landscape are often described using landscape metrics \cite{Gustafson1998,Uuemaa2009,Uuemaa2013,Gustafson2019}.
These metrics allow the comparison of different landscapes, quantification of temporal and spatial landscape changes and investigation of interactions between landscape characteristics and ecological processes \cite{Uuemaa2009}.

The introduction of the *FRAGSTATS* in 1995 heavily facilitated the use of landscape metrics software \cite{McGarigal2012,Kupfer2012,Gustafson2019} and the *landscapemetrics* package \cite{Hesselbarth2019a} allows to calculate the most widely used landscape metrics in within the *R* environment.

More recently, surface metrics were suggested as an alternative to landscape metrics for continuous raster data \cite{McGarigal2009}.
The *geodiv* package \cite{Smith2020} allows calculation of gradient surface metrics to facilitate continuous analysis of landscape features.
Additionally, the *belg* package allows calculation of the Boltzmann entropy of a landscape gradient \cite{R-belgpaper}.

Most landscape metrics are a represented by a single number depicting specific characteristics of a local landscape.
Another possibility is to derive spatial signatures - a multi-value representation of landscape composition and configuration, such as a co-occurrence histogram.
<!-- MH: Do we have a reference here @Jakub? -->
Spatial signatures calculated for many landscapes can be compared using one of a set of existing distance measures (e.g. Euclidian, Manhattan, Mahlanobis).
<!-- LJG added some examples, but not 100% if they're the distances you're thinking of -->
This enables several types of spatial analysis on categorical raster data, such as searching for similar landscapes, detecting changes between landscape patterns, and spatial clustering of landscapes based on their composition and configuration.
All of the spatial signatures methods mentioned above are implemented in the *motif* package \cite{R-motif}.

#### Spatial statistics

Spatial statistics are complimentary to landscape metrics, and can be used to analyze patterns in continuous data (e.g., normalized difference vegetation index, disturbance intensity, topography). 
In landscape ecology, spatial statistics has three key uses: i) detecting and correcting for spatial autocorrelation; ii) quantifying and comparing landscape patterns; iii) interpolating data. 

Point pattern analysis uses event-level data, such as locations of individuals, and links the spatial pattern to the ecological process.
The *spatstat* package \cite{R-spatstat} contains functionality for point pattern analysis, including exploratory analysis; simulation of point process models; and modeling fitting, inference, and diagnostics. 
A comprehensive textbook covering both theoretical background as well as applied examples can be found here \cite{Baddeley2015}.

Distance-based methods allow to detect and correct for spatial autocorrelation in data.
It is key to do so as landscape data are highly spatially autocorrelated, and this non-independence can affect inferences from statistical modeling. 
The *spdep* package \cite{Bivand2013} has methods for quantifying multiple metrics of spatial autocorrelation and correcting these in a spatial autoregressive model.
The *rinla* \cite{rue2009approximate} (\url{https://www.r-inla.org}) and *inlabru* \cite{R-inlabru} packages also provide functionality for modeling of spatially structured data. 

Finally, the spatial structure of continuous landscapes can be quantified and compared with geostatistical tools, such as variograms and correlograms. 
R packages *geoR* \cite{R-geoR} and *gstat* \cite{R-gstat} provide functionality for this type of analysis, as well as interpolation methods, known as (co-)kriging.
Geostatistics also allows for spatial data simulations.
<!-- MH: I am not sure if I understand the last sentence, but is it worth to reference the NLM section here? -->

#### Species distribution modeling {#sec:SDM}

Species distribution modeling (SDM) examines how landscape patterns (e.g., habitat suitability or resources availability) influence and determine the patterns of species' distributions, mainly to infer ecological processes and predict future species' distributions \cite{Wiersma2011}.
Originated in the 1970s, SDM has experienced numerous methodological advancement, and a numerous body of literature exists today \cite{Zimmermann2010,Norberg2019}.
Additionally, textbooks introducing basic concepts of SDM in *R* exists \cite{Guisan2017,Fletcher2019}.

Because the used modeling approaches are diverse \cite{Hooten2011,Kerr2011,Fletcher2019}, there is also a large number of *R* packages used for SDMs.
Popular approaches and packages include generalized linear models using, e.g., the *stats* \cite{RCoreTeam2019} package; generalized additive models using, e.g., the *mgcv* \cite{Wood2017} or *lme4* \cite{Bates2015} package; classification and regression trees (CART) using, e.g., the *rpart* \cite{Therneau2019}, *randomForest* \cite{Liaw2002} or *ranger* \cite{Wright2017} package or multivariate data analysis using , e.g., the *ade4* \cite{Dray2007} or *vegan* \cite{Oksanen2019} package.
Also, packages specifically designed for SDM exist, including the *dismo* \cite{Hijmans2017}, *sdm* \cite{Naimi2016}, *ecospat* \cite{Broennimann2020}, *biomod2* \cite{Thuiller2020}, *PresenceAbsence* \cite{Freeman2008}, or *zoon* \cite{Golding2018} packages. 
Additionally, packages such as *ENMeval* \cite{R-enmeval} provide functionality for model tuning and evaluation. 

Related to SDMs, there is a growing number of *R* packages to analyze data from tracked animals, to study their movement characteristics, space use, and interaction with other animals and the environment.
These analyses often use results of landscape ecological analyses as predictor variables to explain variation in space use \cite{signer2015}, behavioral states \cite{langrock2012}, or habitat selection \cite{fieberg2020}.
Widely used *R* packages include *ctmm* \cite{calabrese2016} and *adehabitatHR* \cite{Calenge2006} for home-range estimation, *moveHMM* \cite{michelot2016} for the classification of behavioral states, and *amt* \cite{Signer2019} for habitat selection.
A recent and very comprehensive overview of R packages for the analysis of animal movement data is given by \cite{joo2020}.

#### Connectivity {#sec:connectivity}

Connectivity is one of the core elements of landscape structure \cite{Taylor1993} and thus one of the core concepts of landscape ecology \cite{With2019}.
Landscape connectivity describes how landscape characteristics facilitate or hinder the movement of species \cite{Tischendorf2000} or other aspects of mobility, such as dispersal, gene or nutrient flow \cite{With2019}.
While structural connectivity focuses only on landscape characteristics (e.g., movement corridors, barriers), functional connectivity also includes behavior characteristics of the species such as habitat associations and dispersal distances \cite{Tischendorf2000,With2019}.
Given its broad concept, many different measures of connectivity exist \cite{Kindlmann2008}.
At the patch level, structural connectivity can be measured using nearest-neighbor distances or characterizations of the patch neighborhood (e.g., amount of suitable habitat) \cite{Kindlmann2008,With2019}.
Such measures are provided within the *landscapemetrics* package (see \ref{sec:landscape_metrics}).
Furthermore, the *lconnect* package \cite{Mestre2019} and *Makurhini* package \cite{Godinez-Gomez2020} provide several landscape connectivity metrics.
Another way to describe connectivity is based on graph theory with the advantage that functional connectivity can also be included \cite{Kindlmann2008}.
In graph theory \cite{Laita2011}, landscapes are described by nodes (i.e., habitat patches) connected by and functional connections called links (or edges) \cite{Laita2011}.
The *grainscape* package \cite{Chubaty2020} provides a tool to model connectivity based on spatially explicit networks.
More generally, the *igraph* package \cite{Csardi2006} provides functionality for graph theoretic analyses.
Resistance surfaces and least-cost paths are other tools to model functional connectivity which include attributes of the matrix.
The resistance surface describes the effects of facilitating or hindering the landscape's characteristics for an organism moving within it \cite{Adriaensen2003}.
Least-cost paths can be calculated using the *gdistance* package \cite{vanEtten2017}.
Absorbing Markov chains quantify landscape connectivity as the combination of movement and mortality based on the landscape characteristics \cite{Fletcher2019a}, and is provided by the recently published *samc* package \cite{Marx2020}.

#### Landscape genetics {#sec:landscape_genetics}

Landscape genetics investigates how characteristics of landscapes interact with gene flow, genetic drift, and selection \cite{Manel2003}.
Such insights improve our understanding of metapopulation dynamics, speciation, species' distributions, and conservation \cite{Storfer2007}.
By explicitly including landscape characteristics, landscape genetics provides a more detailed analysis than more abstract concepts (e.g., metapopulation genetics) \cite{Holderegger2006}.
As a result of its interdisciplinarity, landscape genetics draws together methods from multiple fields, including landscape ecology, spatial statistics, geography, and population genetics \cite{Storfer2007}.

Since describing connectivity between two locations is one of the fundamental steps of landscape genetics, all packages useful for connectivity (see \ref{sec:connectivity}) are also important for landscape genetics.
Further functionality for landscape genetics such as quantifying and analysing population genetic structure, and hierarchical decomposition analysis can be found in the *graphs4lg* \cite{Savary2020}, *PopGenReport* \cite{Adamack2014,Gruber2015}, *HierDpart* packages \cite{Qin2019}, or *GeNetIt* \cite{Murphy2010}.

#### Neutral landscape models {#sec:NLM}

Neutral landscape models are used to create structured landscapes in the absence of specific ecological and landscape processes as null models against which hypotheses including specific ecological and landscape processes can be tested statistically \cite{Gardner1987,With1997}.
Because neutral landscape models are not based on ecological and landscape processes, many different generic algorithms to create landscapes can be found across various *R* packages.
A comprehensive collection of algorithms to simulate neutral landscape models specifically designed for landscape ecology can be found in the *NLMR* package \cite{Sciaini2018}.
Furthermore, the *RandomFields* package \cite{Schlather2015} allows to simulate Gaussian fields, which could be used as neutral landscape models.

```{=tex}
\begin{table}

\caption{Overview of commonly used R packages for spatial data and landscape ecology. Packages are sorted by their major application task.}

\begin{tabularx}{450pt}{lrXr}

\hline
Task & R package & Describtion & Reference \\
\hline
\multirow{8}{*}{Spatial data} & raster & Raster data handling and analysis & \cite{Hijmans2019} \\
& terra & Raster (and some vector) data handling and analysis & \cite{R-terra} \\
& stars & Spatiotemporal raster data handling and analysis & \cite{Pebesma2019} \\
& fasterize & Polygon to raster conversion & \cite{Ross2020} \\
& rasterDT & Faster alternatives for some raster functions & \cite{OBrien2020} \\
& exactextractr & Summarize raster values over polygonal areas & \cite{Baston2020} \\
& sp & Vector data handling and analysis & \cite{Pebesma2005,Bivand2013} \\
& sf & Vector data handling and analysis & \cite{Pebesma2018} \\
\hline
\multirow{6}{*}{Spatial data download} & rnaturalearth & Download region and country data & \cite{South2017} \\
& elevatr & Download elevation data & \cite{R-elevatr} \\
& rgbif & Download biodiversity data & \cite{R-rgbif} \\
& BIEN & Download plant diversity, function and distribution data & \cite{Maitner2020} \\
& marmap & Download and manipulate bathymetric data & \cite{Pante2013} \\
& FedData & Download geospatial data from US federal sources & \cite{R-FedData} \\
& getlandsat & Download satellite data from Landsat 8 & \cite{Chamberlain2018} \\
& MODIS & Download satellite data from MODIS & \cite{Mattiuzzi2020} \\
& sen2r & Download satellite data from Sentinel & \cite{R-sen2r} \\
\hline
\multirow{7}{*}{Creating maps} & rasterVis & Vizualuzation of raster data & \cite{Lamigueiro2020} \\
& ggspatial & Spatial extension for ggplot2 & \cite{Dunnington2020} \\
& cartography & Create cartographic maps & \cite{Giraud2016} \\
& tmap & Create thematic maps & \cite{Tennekes2018} \\
& mapview & Interactive viewing of spatial data & \cite{R-mapview} \\
& leaflet & Create interactive web maps & \cite{R-leaflet} \\
& rayshader & Create 2D and 3D data visualizations & \cite{Morgen-Wall2020} \\
\hline
\multirow{4}{*}{\shortstack[l]{Quantifying landscape\\characteristics}} & landscapemetrics & Quantify categorical landscape patterns & \cite{Hesselbarth2019a} \\
& belg & Calculate the Boltzmann entropy & \cite{R-belgpaper} \\
& motif & Pattern-based spatial analysis & \cite{R-motif} \\
& geodiv & Quantify continuous landscape patterns & \cite{Smith2020} \\
\hline
\multirow{6}{*}{\shortstack[l]{Spatial statistics}} & spatstat & Point pattern analysis & \cite{R-spatstat} \\
& spdep & Quantify and correct for spatial autocorrelation & \cite{Bivand2013} \\
& rinla & Fitting Bayesian spatio-temporal models using INLA & \cite{rue2009approximate} \\
& inlabru & Fitting Bayesian spatio-temporal models using INLA & \cite{R-inlabru} \\
& geoR & Variograms, correlograms and (co-)kriging & \cite{R-geoR} \\
& gstat & Variograms, correlograms and (co-)kriging & \cite{R-gstat} \\
\hline
\multirow{8}{*}{\shortstack[l]{Species distribution\\modeling}} & dismo & Methods for species distribution modeling & \cite{Hijmans2017} \\
& sdm & Species distribution models using individual and community-based approaches & \cite{Naimi2016} \\
& ecospat & Species distribution, niche quantification and community assembly & \cite{Broennimann2020} \\
& biomod2 & Species distribution modeling, ensemble of models and ensemble forecasting & \cite{Thuiller2020} \\
& PresenceAbsence & Evaluating of presence-absence models & \cite{Freeman2008} \\
& zoon & Reproducible and remixable species distribution modelling & \cite{Golding2018} \\
& ENMeval & Model tuning and evaluation & \cite{R-enmeval} \\
& adehabitatHR, adehabitatHS & Home range and habitat selection modelling & \cite{Calenge2006} \\
& amt & Manage and analyze animal movement data &\cite{Signer2019} \\
& ctmm & Fit continuous time movement models &\cite{calabrese2016} \\
& moveHMM & Fit hidden Markov models to movement data &\cite{michelot2016} \\
\hline
\multirow{5}{*}{Connectivity} & lconnect & Calculate landscape connectivity metrics & \cite{Mestre2019} \\
& Makurhini & Calculate fragmentation and landscape connectivity indices & \cite{Godinez-Gomez2020} \\
& grainscape & Calculate minimum planar graph and grains of connectivity models & \cite{Chubaty2020} \\
& gdistance & Distances and routes on geographical grids & \cite{vanEtten2017} \\
& samc & Functions for working with absorbing Markov chains & \cite{Marx2020} \\
\hline
\multirow{4}{*}{Landscape genetics} & graph4lg & Build graphs for landscape genetics analysis & \cite{Savary2020} \\
& PopGenReport & Framework to analyse population genetic data & \cite{Adamack2014,Gruber2015} \\
& HierDpart & Calculating and decomposing hierarchical diversity metrics & \cite{Qin2019} \\
& GeNetIt & Spatial graph-theoretic genetic gravity models & \cite{Murphy2010} \\
\hline
\multirow{4}{*}{various} & NLMR & Simulate neutral landscape models & \cite{Sciaini2018} \\
& RandomFields & Simulation and analysis of random fields & \cite{Schlather2015} \\
& landscapetools & Utility functions for raster data & \cite{Sciaini2018}  \\
& grainchanger & Data aggregation methods for raster data & \cite{Graham2019} \\
\hline

\end{tabularx}

\label{tab:packages}

\end{table}
```
# Survey of R usage by landscape ecology community

```{r participation, include = FALSE}
digits <- 1

# number of people that took part
n_people <- nrow(answers)

# current position
current_position <- dplyr::group_by(answers, position) %>%
  dplyr::summarise(n_rel = n() / n_people * 100) %>%
  dplyr::mutate(n_rel = round(n_rel, digits = digits)) %>%
  dplyr::arrange(-n_rel)

# how often do you use R?
usage_freq <- dplyr::group_by(answers, usage_freq) %>%
  dplyr::summarise(n_rel = n() / n_people * 100) %>%
  dplyr::mutate(n_rel = round(n_rel, digits = digits)) %>%
  dplyr::arrange(-n_rel)

# expertise
expertise <- dplyr::group_by(answers, expertise) %>%
  dplyr::summarise(n_rel = n() / n_people * 100) %>%
  dplyr::mutate(n_rel = round(n_rel, digits = digits)) %>%
  dplyr::arrange(-n_rel)

# own package
own_package <- dplyr::group_by(answers, own_package) %>%
  dplyr::summarise(n_rel = n() / n_people * 100) %>%
  dplyr::mutate(n_rel = round(n_rel, digits = digits)) %>%
  dplyr::arrange(-n_rel)
```

To better understand how the landscape ecology community uses *R*, we conducted a short survey using mailing lists and social media to reach the community.
In total, the survey was answered by `r n_people` participants, of which the majority were either "PhD students" (`r current_position[[1, 2]]`%), followed by "Post-Docs" (`r current_position[[2, 2]]`%) and "Professors" (`r current_position[[3, 2]]`%).
Other, less frequent answers were "Data scientists", "None of the above", "Government employees" "Master's degree student" and "Bachelor's degree student" (in decreasing order).

Most people use *R* either "daily" (`r usage_freq[[1, 2]]`%) or a "few times a week" (`r usage_freq[[2, 2]]`%).
Almost half of all participants described themselves as "advanced" users (`r expertise[[1, 2]]`%), while `r expertise[[2, 2]]`% described themselves as "intermediate" users.
Related to this, about half of the participants either implemented their own package (`r own_package[[3, 2]]`%) or plan to do so in the future (`r own_package[[2, 2]]`%) and most of these packages are hosted on *GitHub* and/or *CRAN*.

```{r research-topics, include = FALSE}

major_topics <- unlist(str_split(answers$major_topic, pattern = ","))

major_topics <- str_trim(major_topics)

major_topics <- str_to_lower(major_topics)

major_topics[major_topics == "-"] <- NA

topics_df <- tibble(topics = major_topics) %>%
  dplyr::group_by(topics) %>%
  dplyr::summarise(n = dplyr::n()) %>%
  dplyr::mutate(n_rel = n / sum(n) * 100,
                topics_reclass = dplyr::case_when(n >= 5 ~ topics,
                                                  n < 5 ~ "others")) %>%
  dplyr::group_by(topics_reclass) %>%
  dplyr::summarise(n_rel = sum(n_rel)) %>%
  dplyr::mutate(label = paste0(round(n_rel, digits = 1), "%"),
                col = dplyr::case_when(topics_reclass == "others" ~ 0,
                                       topics_reclass != "others" ~ 1),
                col = factor(col)) %>%
  dplyr::arrange(-n_rel)

# change ordering
new_levels <- c("others", rev(topics_df$topics_reclass[!topics_df$topics_reclass == "others"]))

# reorder levels
topics_df$topics_reclass <- factor(topics_df$topics_reclass, levels = new_levels)

# major_topic
ggplot_topics <-  ggplot(data = topics_df) +
  geom_bar(aes(y = topics_reclass, x = n_rel, fill = col), stat = "identity") +
  # geom_text(aes(y = topics_reclass, x = n_rel, label = label, col = col),
  #           nudge_x = 1.25, size = 2.5) +
  theme_classic(base_size = base_size) +
  theme(plot.title.position = "plot") +
  scale_x_continuous(breaks = seq(0, 20, 5), limits = c(0, 20)) +
  scale_fill_manual(values = c("grey50", "black")) +
  scale_colour_manual(values = c("grey50", "black")) +
  guides(fill = FALSE, colour = FALSE) +
  labs(x = "Number of task mentioned [%]", y = NULL,
       title = "Which terms describe your\nmajor research topics the best?")

```

We asked the participants to select which terms describe their research topics the best, and options that were selected by more than 10% of participants included "biodiversity", followed by "land use management", "landscape connectivity", and "nature conservation" (Fig. \@ref(fig:fig-survey) A)).

```{r tasks, include = FALSE}
# get data
important_tasks <- unlist(str_split(answers$important_tasks, pattern = ","))

# remove empty space at beginning
important_tasks <- str_trim(important_tasks)

# make sure all lower case
important_tasks <- str_to_lower(important_tasks)

# shorten labels
important_tasks[important_tasks == "(pre-)processing of spatial data"] <- "(pre-)processing data"

important_tasks[important_tasks == "spatial point pattern analysis"] <- "point pattern analysis"

important_tasks[important_tasks == "programming individual based models"] <- "individual based modelling"

important_tasks[important_tasks == "creating neutral landscape models"] <- "neutral landscape models"

important_tasks[important_tasks == "quantifying landscape characteristics (e.g. landscape metrics)"] <- "quantifying landscape characteristics"

# # add line breaks
# important_tasks <- str_replace_all(important_tasks, pattern = " ", replacement = "\n")

# create data.frame
tasks_df <- tibble(tasks = important_tasks) %>%
  dplyr::group_by(tasks) %>%
  dplyr::summarise(n = dplyr::n()) %>%
  dplyr::mutate(n_rel = n / sum(n) * 100,
                tasks_reclass = dplyr::case_when(n >= 5 ~ tasks,
                                                 n < 5 ~ "others")) %>%
  dplyr::group_by(tasks_reclass) %>%
  dplyr::summarise(n_rel = sum(n_rel)) %>%
  dplyr::mutate(label = paste0(round(n_rel, digits = 1), "%"),
                col = dplyr::case_when(tasks_reclass == "others" ~ 0,
                                       tasks_reclass != "others" ~ 1),
                col = factor(col)) %>%
  dplyr::arrange(-n_rel)

# change ordering
new_levels <- c("others", rev(tasks_df$tasks_reclass[!tasks_df$tasks_reclass == "others"]))

# reorder levels
tasks_df$tasks_reclass <- factor(tasks_df$tasks_reclass, levels = new_levels)

ggplot_tasks <- ggplot(data = tasks_df) +
  geom_bar(aes(y = tasks_reclass, x = n_rel, fill = col), stat = "identity") +
  # geom_text(aes(y = tasks_reclass, x = n_rel, label = label, col = col),
  #           nudge_x = 1.25, size = 2.5) +
  theme_classic(base_size = base_size) +
  theme(plot.title.position = "plot") +
  scale_x_continuous(breaks = seq(0, 20, 5), limits = c(0, 20)) +
  scale_fill_manual(values = c("grey50", "black")) +
  scale_colour_manual(values = c("grey50", "black")) +
  guides(fill = FALSE, colour = FALSE) +
  labs(x = "Number of task mentioned [%]", y = NULL,
       title = "Which are the most important\ntasks to your workflow?")
```

Next, we were interested in the most important tasks to the workflow of the participants.
Not surprisingly, "(pre-)processing of data", "spatial statistics", and "creating maps" were the most selected options (Fig. \@ref(fig:fig-survey) B).
The available options seemed to describe the most important task to the workflow quite well since only very few participants selected the "others" option (all options with less than five total answers were classified as "others").

```{r data-model, include = FALSE}
# data model
data_model <- dplyr::group_by(answers, data_model) %>%
  dplyr::summarise(n_rel = n() / n_people * 100) %>%
  dplyr::mutate(n_rel = round(n_rel, digits = digits)) %>%
  dplyr::arrange(-n_rel)
```

```{r packages, include =FALSE}

# split answers r packages
r_packages <- unlist(str_split(answers$r_packages, pattern = ","))
r_packages <- unlist(str_split(r_packages, pattern = ";"))
r_packages <- unlist(str_split(r_packages, pattern = "\\*"))
r_packages <- str_trim(r_packages)

# clean some special cases
r_packages[str_detect(r_packages, pattern = "landscape metrics")] <- "landscapemetrics"
r_packages[str_detect(r_packages, pattern = "spectre*")] <- "spectre"
r_packages[str_detect(r_packages, pattern = "map tools")] <- "maptools"
r_packages[str_detect(r_packages, pattern = "gdal and many more")] <- "rgdal"
r_packages[str_detect(r_packages, pattern = "I would like to know")] <- "NA"
r_packages[str_detect(r_packages, pattern = "no")] <- "NA"
r_packages[str_detect(r_packages, pattern = "currently none")] <- "NA"
r_packages[!str_detect(r_packages, pattern = "")] <- "NA"

# split last packages
r_packages <- unlist(str_split(r_packages, pattern = " "))

# remove NA answers
r_packages <- r_packages[!str_detect(r_packages, pattern = "NA")]

# make sure all are lower case
r_packages <- str_to_lower(r_packages)

# remove escape characters
r_packages <- str_remove_all(r_packages, pattern = "\"")

# create data.frame
r_packages_df <- tibble(r_package = r_packages) %>%
  dplyr::group_by(r_package) %>%
  dplyr::summarise(n = dplyr::n()) %>%
  dplyr::mutate(n_rel = n / sum(n) * 100,
                r_package_reclass = dplyr::case_when(n >= 5 ~ r_package,
                                                     n < 5 ~ "others")) %>%
  dplyr::group_by(r_package_reclass) %>%
  dplyr::summarise(n_rel = sum(n_rel)) %>%
  dplyr::mutate(label = paste0(round(n_rel, digits = 1), "%"),
                col = dplyr::case_when(r_package_reclass == "others" ~ 0,
                                       r_package_reclass != "others" ~ 1),
                col = factor(col)) %>%
  dplyr::arrange(-n_rel)

# change ordering
new_levels <- c("others", rev(r_packages_df$r_package_reclass[-1]))

# reorder levels
r_packages_df$r_package_reclass <- factor(r_packages_df$r_package_reclass,
                                          levels = new_levels)

ggplot_packages <- ggplot(data = r_packages_df) +
  geom_bar(aes(y = r_package_reclass, x = n_rel, fill = col), stat = "identity") +
  # geom_text(aes(y = r_package_reclass, x = n_rel, label = label, col = col),
  #           nudge_x = 2, size = 2.5) +
  theme_classic(base_size = base_size) +
  theme(plot.title.position = "plot") +
  scale_x_continuous(breaks = seq(0, 35, 5), limits = c(0, 36)) +
  scale_fill_manual(values = c("grey50", "black")) +
  scale_colour_manual(values = c("grey50", "black")) +
  guides(fill = FALSE, colour = FALSE) +
  labs(x = "Number of package mentioned [%]", y = NULL,
       title = "List the three R packages related\nto landscape ecology you use the most")
```

More people use the raster data model (`r data_model[[1, 2]]`%) in comparison to the vector data model (`r data_model[[2, 2]]`%).
This was also represented in the most used *R* packages (Fig. \@ref(fig:fig-survey) C)).
When asked for the three most used packages, participants of the survey listed `r length(unique(r_packages))` packages in total.
The *raster* package was mentioned the most, followed by the *sf* package.
Both packages are designed for basic and advanced data handling and processing of raster and vector data, respectively, representing the results of Fig. \@ref(fig:fig-survey) C).
Nevertheless, the large availability and usage of different *R* packages across the community can be seen in the large "others" option (packages mentioned by less than 5 participants; `r round(r_packages_df[[1, 2]], 2)`%).

```{r usefulness, include = FALSE}
# create vector with classses

classes <- c("very useful", "useful", "intermediate",
             "not useful", "not useful at all")

# create data.frame
usefulness_df <- dplyr::group_by(answers, usefulness) %>%
  dplyr::summarise(n = dplyr::n()) %>%
  dplyr::mutate(n_rel = n / sum(n) * 100) %>%
  tibble::add_row(usefulness = 1, n = 0, n_rel = 0) %>%
  dplyr::arrange(-usefulness) %>%
  dplyr::mutate(label = paste0(round(n_rel, digits = 1), "%"),
                usefulness_class = classes,
                usefulness_class = factor(usefulness_class,
                                          levels = rev(classes))) %>%
  dplyr::arrange(-n_rel)

good_eval <- dplyr::filter(usefulness_df, usefulness %in% c(5, 4)) %>%
  dplyr::pull(n_rel) %>%
  sum() %>%
  round(digits = 2)

bad_eval <- dplyr::filter(usefulness_df, usefulness %in% c(3, 2, 1)) %>%
  dplyr::pull(n_rel) %>%
  sum() %>%
  round(digits = 2)

ggplot_usefulness <- ggplot(data = usefulness_df) +
  geom_bar(aes(x = usefulness_class, y = n_rel),
           stat = "identity", fill = "black") +
  theme_classic(base_size = base_size) +
  theme(plot.title.position = "plot") +
  # scale_x_continuous(breaks = seq(0, 60, 10), limits = c(0, 60)) +
  guides(fill = FALSE, colour = FALSE) +
  labs(x = NULL,
       title = "How useful do you think is R currently\nfor landscape ecology?",
       y = "Number of participants [%]") +
  coord_flip()
```

Lastly, when asked how useful *R* is currently for landscape ecology, the vast majority of participants answered with either "very useful" or "useful" (summarized `r good_eval`%) and only very few participants evaluated *R* as "intermediate", "not useful" or "not useful at all" (summarized `r bad_eval`%; Fig. \@ref(fig:fig-survey) D)).

```{r fig-survey, echo = FALSE, fig.align="center", fig.cap = "Results of the online survey about open-source software tools in R for landscape ecology. Results include a) which terms describe major reserach topics the best, b) the most important workflow task, c) the most used R packages and d) the overall usefulnes or R for landscape ecology. The 'others' category includes all answers with less than five total mentions.", warning=FALSE, out.width="100%"}

(ggplot_topics | ggplot_tasks) / (ggplot_packages | ggplot_usefulness) +
  # plot_layout(heights = c(2, 3)) +
  plot_annotation(tag_levels = "a")

```

The survey also included a section in which participants could list methods and tools currently missing in *R* and answers to this question were very diverse.

```{r comments, include = FALSE}

missing_methods <- answers$missing_methods[!is.na(answers$missing_methods)]

missing_methods <- str_to_lower(missing_methods)

# no answer, no missing packages
id_na <- c("not sure", "not sure right now",
           "i have no additional needs for my current workflow", "none that i can think of",
           "i would like to know", "none", "i still have to fully understand what is there",
           "i don't know, sorry!", "r havent fail me yet", "na",
           "i'm not missing anything at present.", "no posso responder",
           "no", "unsure", "have not yet identified any.", "no package missing",
           "not enough overview to answer this", "?", "i am currently missing no methods",
           ";", "nothing yet", "i'm thinking", "nil", "none", 
           "nothing really but prefer to do programming in python", "i dont miss any")


length(id_na) / nrow(answers) * 100

missing_methods <- missing_methods[!missing_methods %in% id_na]

# classify answers as good as possible
methods_performance <- missing_methods[c(2, 4, 8, 9, 10, 21, 23, 27, 30, 33, 41, 45,
                                         48, 56)]

perc_performance <- round(length(methods_performance) / nrow(answers) * 100, 1)

methods_viz <- missing_methods[c(3, 7, 13, 22, 29, 33, 41, 57, 58)]

perc_viz <- round(length(methods_viz) / nrow(answers) * 100, 1)

methods_characterisation <- missing_methods[c(7, 14, 20, 24, 39, 42, 47, 51, 59, 65)]

perc_characterisation <- round(length(methods_characterisation) / nrow(answers) * 100, 1)

# methods_connectivity <- missing_methods[c(12, 17, 26, 31, 35, 36, 40, 51)]
#
# perc_connectivity <- round(length(methods_connectivity) / nrow(answers) * 100, 1)

```

Overall, `r round(length(id_na) / nrow(answers) * 100, digits)`% of the participants reported that currently no packages and functionality are missing for them or they lack the overview to answer the question.
There were three most common topics across the answers of the participants.
Firstly, many participants (`r perc_performance`%) wished for a better computational performance of *R* in terms of speed and required RAM, especially for larger data.
Secondly, participants are missing specific approaches to quantify landscape characteristics (such as surface metrics), or are wishing for an improvement of currently available approaches to quantify landscape characteristics (`r perc_characterisation`%).
Thirdly, many participants (`r perc_viz`%) are currently missing advanced and easy-to-apply methods to create high-quality maps or other visualization-related functionality.

# Conclusions

<!--intro-->
Since its first introduction in 1995, *R* has come a long way from an exclusively statistical programming language to a powerful landscape ecology tool.
Today, many *R* packages, mainly developed by the community itself, provide a vast collection of functions and algorithms aimed at spatial data handling and analysis.
The highly dynamic development of *R* packages for landscape ecology also shows the strength of open-source software with its high innovation, transparency, reliability, and longevity.
However, since landscape ecology constantly develops and improves, the *R* programming language and its packages need to change and adapt to these changes.

<!--a paragraph summarizing possibilities-->
A comprehensive collection of *R* software packages exist to handle the most common tasks of landscape ecology. 
Because it is possible to import, modify, analyze, and visualize spatial data all in the same programming environment, *R* allows for transparent and reproducible workflows.
Additionally, this also allows users to easily interchange, modify, or adapt methods from other related and unrelated fields.

<!--a paragraph summarizing the survey-->
The survey revealed that the landscape ecology community is overall satisfied with the capabilities of the *R* programming language for landscape ecology. 
Furthermore, the survey showed the that many members of the landscape ecology community actively develop *R* packages themselves, demonstrating that tools are constantly added and updated.

<!--a paragraph about missing features/future work-->
Landscape ecology combines many different research topics and methodological approaches and most of them heavily rely on spatial data.
While the *R* programming language is generally well suited to handle, analyze and visualize spatial data, the increasing availability of large data sets also leads to the challenges of increased computational demands, in terms of computational time as well as memory requirements, the *R* programming language has to face. 
Furthermore, as the individual fields collected under the umbrella of landscape ecology develop, so need the *R* packages related to those fields.
But as the development of *R* packages over the past years clearly demonstrated, the landscape ecology community is ready to face these challenges.

## Acknowledgments

<!-- MH: Make sure to update all sections  -->

We are thankful to all members of the 'Coastal Ecology and Conservation Lab' at University of Michigan for comments on an early draft of the manuscript.

#### Conflict of interest

MHKH and JN are authors of the *landscapemetrics* and *landscapetools* package.
JN is author of *belg* and *motif* package. JS is author of the *amt* package. LJG is author of the *grainchanger* package.

#### Funding

<!-- MH: Add UMich Funding? -->

MHKH was supported by the German Research Association (DFG) Research Training Group 1644 'Scaling Problems in Statistics', grant number 152112243.

#### Author contributions

MHKH and JN designed the survey form and analyzed the responses of the participants.
MHKH and JN drafted the manuscript with contributions of JS and LJG and all authors contributed critically to the manuscript and gave final approval for publication.
We used the 'sequence--determines--credit' approach (SDC) for the sequence of authors.

#### Human and Animal Rights and Informed Consent

This article does not contain any studies with human or animal subjects performed by any of the authors.
